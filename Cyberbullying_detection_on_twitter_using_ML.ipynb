{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arshia132/Detection-of-Cyberbulling-on-twitter-dataset-using-Machine-learning/blob/main/Cyberbullying_detection_on_twitter_using_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKDzBWkmuPJk"
      },
      "outputs": [],
      "source": [
        "#Libraries for general purpose\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X7Kxj8gvGlt",
        "outputId": "b9ab7739-9310-45b4-e566-a9fde5079e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.1.0.tar.gz (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 8.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.1.0-py3-none-any.whl size=212392 sha256=932cf6758ca53b66c70a93d7a5388d8ce78d0a37019508b1f999d507f935f040\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/75/99/51c2a119f4cfd3af7b49cc57e4f737bed7e40b348a85d82804\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWZW4iEzW_HL",
        "outputId": "9a2f562f-4ee5-4e31-c17b-3e46002aedcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement nlkt (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for nlkt\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install nlkt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRDfa9IMXnRb"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acHoJEWovtaN",
        "outputId": "2f15a8d6-761e-4607-d98c-269c6880dd59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBEbEO3_uzS3"
      },
      "outputs": [],
      "source": [
        "#Text cleaning\n",
        "import re, string\n",
        "# import emoji\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zprW1at1vygN"
      },
      "outputs": [],
      "source": [
        "#Data preprocessing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNIAOyGFwBFV"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5N_u7RdwGf9"
      },
      "outputs": [],
      "source": [
        "#PyTorch LSTM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIyudTnawI8P"
      },
      "outputs": [],
      "source": [
        "#Tokenization for LSTM\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtNU_b2JwYBN",
        "outputId": "16cb8b7d-ad7e-4f75-f069-831b3764456c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgzVkM7LwN6N"
      },
      "outputs": [],
      "source": [
        "#Transformers library for BERT\n",
        "import transformers\n",
        "from transformers import BertModel\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IDD_9j-wfF1"
      },
      "outputs": [],
      "source": [
        "#Seed for reproducibility\n",
        "import random\n",
        "\n",
        "seed_value=42\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcLZAVDfYEMB"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "MXaRye9uwl5E",
        "outputId": "3799d1fa-3bb9-4c5d-f1df-6be542c043b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.despine()\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EvSi31Hw069"
      },
      "source": [
        "**Data Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptEnLVKgwtb9",
        "outputId": "52399a39-66c6-4c3c-8fd3-23202f12865f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD4CHbUDgEfJ"
      },
      "outputs": [],
      "source": [
        "df = \"/content/drive/MyDrive/Data/cyberbullying_tweets.csv\"\n",
        "df_bonus = pd.read_csv(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Jx7pz_tVh6aA",
        "outputId": "62c2d6d1-c21f-4b20-c28a-7bb62d2963ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-61f7e2d4-e09d-4dee-ab5c-b0f2e5140cfb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cyberbullying_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61f7e2d4-e09d-4dee-ab5c-b0f2e5140cfb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61f7e2d4-e09d-4dee-ab5c-b0f2e5140cfb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61f7e2d4-e09d-4dee-ab5c-b0f2e5140cfb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          tweet_text cyberbullying_type\n",
              "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
              "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
              "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
              "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
              "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_bonus.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH49dM4ciCfx",
        "outputId": "d0b73102-1a8e-4bfb-9d88-a1edede7deb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of                                               tweet_text cyberbullying_type\n",
              "0      In other words #katandandre, your food was cra...  not_cyberbullying\n",
              "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
              "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
              "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
              "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
              "...                                                  ...                ...\n",
              "47687  Black ppl aren't expected to do anything, depe...          ethnicity\n",
              "47688  Turner did not withhold his disappointment. Tu...          ethnicity\n",
              "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity\n",
              "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity\n",
              "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity\n",
              "\n",
              "[47692 rows x 2 columns]>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_bonus.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kguGNffKiKGw"
      },
      "source": [
        "**First we rename the columns using shorter words for easier reference.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyb7tUkBiJmR"
      },
      "outputs": [],
      "source": [
        "df = df_bonus.rename(columns={'tweet_text': 'text', 'cyberbullying_type': 'sentiment'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZaSbJj-iU3x"
      },
      "source": [
        "**Checking Duplicate tweets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ucwiX0KiYeo",
        "outputId": "bff79d44-0886-4d88-d82c-1be77ff39735"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.duplicated().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLV1z0mMinHZ"
      },
      "source": [
        "**Removing Duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktS5BF-rigaI"
      },
      "outputs": [],
      "source": [
        "df = df[~df.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sef6BJBJikZ4",
        "outputId": "eb50b4a6-d079-403b-b4fb-0743a98b6040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 47656 entries, 0 to 47691\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   text       47656 non-null  object\n",
            " 1   sentiment  47656 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnS2c6wnirlo"
      },
      "source": [
        "**Are the classes balanced?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv7SBehXiqqw",
        "outputId": "6d6de302-ef19-4e00-d363-b94ec4fc1c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "religion               7997\n",
              "age                    7992\n",
              "ethnicity              7959\n",
              "gender                 7948\n",
              "not_cyberbullying      7937\n",
              "other_cyberbullying    7823\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66q7U-LgizyQ"
      },
      "source": [
        "**Tweets text deep cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix-97R1Vbqeg",
        "outputId": "fb85d774-c4e0-49ff-f54d-a2427eb0f0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQAXICV1izQP"
      },
      "outputs": [],
      "source": [
        "#Clean emojis from text\n",
        "# def strip_emoji(text):\n",
        "#      return re.sub(emoji.get_emoji_regexp(), r\"\", text) #remove emoji\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLli16Tpi9QQ"
      },
      "outputs": [],
      "source": [
        "#Remove punctuations, links, stopwords, mentions and \\r\\n new line characters\n",
        "def strip_all_entities(text):\n",
        "    text = text.replace('\\r', '').replace('\\n', ' ').lower() #remove \\n and \\r and lowercase\n",
        "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
        "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
        "    banned_list= string.punctuation\n",
        "    table = str.maketrans('', '', banned_list)\n",
        "    text = text.translate(table)\n",
        "    text = [word for word in text.split() if word not in stop_words]\n",
        "    text = ' '.join(text)\n",
        "    text =' '.join(word for word in text.split() if len(word) < 14) # remove words longer than 14 characters\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhdpqADljChI"
      },
      "outputs": [],
      "source": [
        "#remove contractions\n",
        "def decontract(text):\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLxaElLYjHDh"
      },
      "outputs": [],
      "source": [
        "#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the \"#\" symbol\n",
        "def clean_hashtags(tweet):\n",
        "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
        "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
        "    return new_tweet2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9T2ZgisjLGo"
      },
      "outputs": [],
      "source": [
        "#Filter special characters such as \"&\" and \"$\" present in some words\n",
        "def filter_chars(a):\n",
        "    sent = []\n",
        "    for word in a.split(' '):\n",
        "        if ('$' in word) | ('&' in word):\n",
        "            sent.append('')\n",
        "        else:\n",
        "            sent.append(word)\n",
        "    return ' '.join(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePoCMMegjOYo"
      },
      "outputs": [],
      "source": [
        "#Remove multiple sequential spaces\n",
        "def remove_mult_spaces(text):\n",
        "    return re.sub(\"\\s\\s+\" , \" \", text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGEGU37AjR0q"
      },
      "outputs": [],
      "source": [
        "#Stemming\n",
        "def stemmer(text):\n",
        "    tokenized = nltk.word_tokenize(text)\n",
        "    ps = PorterStemmer()\n",
        "    return ' '.join([ps.stem(words) for words in tokenized])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf4AqB5MjV5h"
      },
      "outputs": [],
      "source": [
        "#Lemmatization\n",
        "#NOTE:Stemming seems to work better for this dataset\n",
        "def lemmatize(text):\n",
        "    tokenized = nltk.word_tokenize(text)\n",
        "    lm = WordNetLemmatizer()\n",
        "    return ' '.join([lm.lemmatize(words) for words in tokenized])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6RQmDcGjZXZ"
      },
      "outputs": [],
      "source": [
        "#Then we apply all the defined functions in the following order\n",
        "def deep_clean(text):\n",
        "    # text = strip_emoji(text)\n",
        "    text = decontract(text)\n",
        "    text = strip_all_entities(text)\n",
        "    text = clean_hashtags(text)\n",
        "    text = filter_chars(text)\n",
        "    text = remove_mult_spaces(text)\n",
        "    text = stemmer(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_gXRpjsnIMn",
        "outputId": "3fd77c77-2f1d-4a88-9cf3-3f1cc56dc4e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S7OY9j-nil4"
      },
      "outputs": [],
      "source": [
        " import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1qr79snbeTR"
      },
      "outputs": [],
      "source": [
        "texts_new = []\n",
        "for t in df.text:\n",
        "    texts_new.append(deep_clean(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grvBlLKidhYJ"
      },
      "outputs": [],
      "source": [
        "df['text_clean'] = texts_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tnJiIYVndm7H",
        "outputId": "93fb7f2d-25fe-4976-c6cb-cb7a9a195c2e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-97da9ef6-47b3-45f4-92e7-674398f30e8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>word katandandr food crapilici mkr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>aussietv white mkr theblock today sunris studi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>classi whore red velvet cupcak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>meh p thank head concern anoth angri dude twitter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>isi account pretend kurdish account like islam...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97da9ef6-47b3-45f4-92e7-674398f30e8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97da9ef6-47b3-45f4-92e7-674398f30e8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97da9ef6-47b3-45f4-92e7-674398f30e8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text          sentiment  \\\n",
              "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
              "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
              "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
              "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
              "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
              "\n",
              "                                          text_clean  \n",
              "0                 word katandandr food crapilici mkr  \n",
              "1  aussietv white mkr theblock today sunris studi...  \n",
              "2                     classi whore red velvet cupcak  \n",
              "3  meh p thank head concern anoth angri dude twitter  \n",
              "4  isi account pretend kurdish account like islam...  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjdANI0kdqVH",
        "outputId": "bd8b1c74-cc16-4f8b-98aa-26288780db28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(47656, 3)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQlChODAdtQ4",
        "outputId": "5e576522-13fd-4f0e-ecb0-5fa9718937ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3058"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"text_clean\"].duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCFN3o07dwWv"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(\"text_clean\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfjO--IYdza7",
        "outputId": "56c42a3d-ae9d-40ff-e4b4-ebf702c3ba10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(44598, 3)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR06WcPtd1wI",
        "outputId": "db88b270-7b73-4bb8-e342-3c105e6bb117"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "religion               7946\n",
              "age                    7884\n",
              "ethnicity              7744\n",
              "not_cyberbullying      7637\n",
              "gender                 7607\n",
              "other_cyberbullying    5780\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x57IR19Qd4TX"
      },
      "outputs": [],
      "source": [
        "df = df[df[\"sentiment\"]!=\"other_cyberbullying\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPTQRL64d7hf"
      },
      "outputs": [],
      "source": [
        "sentiments = [\"religion\",\"age\",\"ethnicity\",\"gender\",\"not bullying\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Jo8gkxfwri"
      },
      "source": [
        "Tweets length analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFJ1v_PMfy0A"
      },
      "outputs": [],
      "source": [
        "text_len = []\n",
        "for text in df.text_clean:\n",
        "    tweet_len = len(text.split())\n",
        "    text_len.append(tweet_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEs0YGXof3Ap"
      },
      "outputs": [],
      "source": [
        "df['text_len'] = text_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVQnWMM4f5q5"
      },
      "outputs": [],
      "source": [
        "df = df[df['text_len'] > 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHiKPrUnf-aC"
      },
      "source": [
        "What about long tweets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QgmsUoJpf82B",
        "outputId": "c7416eaf-31ae-4cbc-8dc0-70fe8f7048fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-74bfa47d-6bbd-49d3-9980-27a0d3f15117\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44035</th>\n",
              "      <td>You so black and white trying to live like a n...</td>\n",
              "      <td>ethnicity</td>\n",
              "      <td>black white tri live like nigger pahahahaha co...</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45165</th>\n",
              "      <td>@hermdiggz: “@tayyoung_: FUCK OBAMA, dumb ass ...</td>\n",
              "      <td>ethnicity</td>\n",
              "      <td>fuck obama dumb ass nigger bitch ltthi whore s...</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33724</th>\n",
              "      <td>... I don't feel guilty for killing him, I jus...</td>\n",
              "      <td>age</td>\n",
              "      <td>feel guilti kill feel guilti enjoy torment sin...</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1317</th>\n",
              "      <td>@EurekAlertAAAS: Researchers push to import to...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>research push import top antibulli program us ...</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47037</th>\n",
              "      <td>@Purely_Ambition: Sooo mad. RT @TracePeterson ...</td>\n",
              "      <td>ethnicity</td>\n",
              "      <td>sooo mad rt fuck obama dumb nigger go switzerl...</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10274</th>\n",
              "      <td>@holliebakerlutz What does that 23% figure rep...</td>\n",
              "      <td>gender</td>\n",
              "      <td>23 figur repres deriv</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5229</th>\n",
              "      <td>are bully sticks for dogs safe</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>bulli stick dog safe</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10314</th>\n",
              "      <td>RT @Mr_LayedBak: I'm not sexist... but women r...</td>\n",
              "      <td>gender</td>\n",
              "      <td>rt sexist women ref</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5237</th>\n",
              "      <td>*hands you a bag of trail mix*</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>hand bag trail mix</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8275</th>\n",
              "      <td>@feministlah @GreenWeiner Picture was gender n...</td>\n",
              "      <td>gender</td>\n",
              "      <td>pictur gender neutral butsur</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37122 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74bfa47d-6bbd-49d3-9980-27a0d3f15117')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74bfa47d-6bbd-49d3-9980-27a0d3f15117 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74bfa47d-6bbd-49d3-9980-27a0d3f15117');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text          sentiment  \\\n",
              "44035  You so black and white trying to live like a n...          ethnicity   \n",
              "45165  @hermdiggz: “@tayyoung_: FUCK OBAMA, dumb ass ...          ethnicity   \n",
              "33724  ... I don't feel guilty for killing him, I jus...                age   \n",
              "1317   @EurekAlertAAAS: Researchers push to import to...  not_cyberbullying   \n",
              "47037  @Purely_Ambition: Sooo mad. RT @TracePeterson ...          ethnicity   \n",
              "...                                                  ...                ...   \n",
              "10274  @holliebakerlutz What does that 23% figure rep...             gender   \n",
              "5229                      are bully sticks for dogs safe  not_cyberbullying   \n",
              "10314  RT @Mr_LayedBak: I'm not sexist... but women r...             gender   \n",
              "5237                      *hands you a bag of trail mix*  not_cyberbullying   \n",
              "8275   @feministlah @GreenWeiner Picture was gender n...             gender   \n",
              "\n",
              "                                              text_clean  text_len  \n",
              "44035  black white tri live like nigger pahahahaha co...       187  \n",
              "45165  fuck obama dumb ass nigger bitch ltthi whore s...       162  \n",
              "33724  feel guilti kill feel guilti enjoy torment sin...       137  \n",
              "1317   research push import top antibulli program us ...       137  \n",
              "47037  sooo mad rt fuck obama dumb nigger go switzerl...       125  \n",
              "...                                                  ...       ...  \n",
              "10274                              23 figur repres deriv         4  \n",
              "5229                                bulli stick dog safe         4  \n",
              "10314                                rt sexist women ref         4  \n",
              "5237                                  hand bag trail mix         4  \n",
              "8275                        pictur gender neutral butsur         4  \n",
              "\n",
              "[37122 rows x 4 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(by=['text_len'], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCgvKhn8gDhx"
      },
      "outputs": [],
      "source": [
        "df = df[df['text_len'] < 100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJLW025vgJUh"
      },
      "source": [
        "Then we also get the length of the longest tweet since it will be useful later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg9mYS-ggMSa",
        "outputId": "3dde6ccf-99ff-4fc1-ea47-b932afd3c455"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len = np.max(df['text_len'])\n",
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "brZwoZT2gPT5",
        "outputId": "e84cd9d4-7d09-4865-c01d-d0c92670eb60"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6e83978e-322e-4a1b-91cd-c9995011e9d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4846</th>\n",
              "      <td>@andrea_gcav: @viviaanajim recuerdas como noso...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>recuerda como nosotra tambin eramo victima del...</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44294</th>\n",
              "      <td>@JasmineLovvee If He Dont Want You Well Fuck H...</td>\n",
              "      <td>ethnicity</td>\n",
              "      <td>dont want well fuck aint worth tear never swea...</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45930</th>\n",
              "      <td>Get off ur ego trip, take off ur rose colored ...</td>\n",
              "      <td>ethnicity</td>\n",
              "      <td>get ur ego trip take ur rose color glass amp g...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21241</th>\n",
              "      <td>And yet God was able to meet their needs using...</td>\n",
              "      <td>religion</td>\n",
              "      <td>yet god abl meet need use radic everyday gener...</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41749</th>\n",
              "      <td>@seijohgorl hoy mami keito AAAA okay so um ika...</td>\n",
              "      <td>ethnicity</td>\n",
              "      <td>hoy mami keito aaaa okay um ikaw talaga one fi...</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44750</th>\n",
              "      <td>What the fuck you dumb nigger I hate you now</td>\n",
              "      <td>ethnicity</td>\n",
              "      <td>fuck dumb nigger hate</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1673</th>\n",
              "      <td>@UMTony lmao! I really wanted to take it down!</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>lmao realli want take</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35335</th>\n",
              "      <td>He's a grade school bully. He's a coward!</td>\n",
              "      <td>age</td>\n",
              "      <td>grade school bulli coward</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3920</th>\n",
              "      <td>Need to let my anger out dude.</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>need let anger dude</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377</th>\n",
              "      <td>@GlennF I have been quietly helping some gator...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>quietli help gator alreadi</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37113 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e83978e-322e-4a1b-91cd-c9995011e9d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e83978e-322e-4a1b-91cd-c9995011e9d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e83978e-322e-4a1b-91cd-c9995011e9d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text          sentiment  \\\n",
              "4846   @andrea_gcav: @viviaanajim recuerdas como noso...  not_cyberbullying   \n",
              "44294  @JasmineLovvee If He Dont Want You Well Fuck H...          ethnicity   \n",
              "45930  Get off ur ego trip, take off ur rose colored ...          ethnicity   \n",
              "21241  And yet God was able to meet their needs using...           religion   \n",
              "41749  @seijohgorl hoy mami keito AAAA okay so um ika...          ethnicity   \n",
              "...                                                  ...                ...   \n",
              "44750       What the fuck you dumb nigger I hate you now          ethnicity   \n",
              "1673      @UMTony lmao! I really wanted to take it down!  not_cyberbullying   \n",
              "35335          He's a grade school bully. He's a coward!                age   \n",
              "3920                      Need to let my anger out dude.  not_cyberbullying   \n",
              "1377   @GlennF I have been quietly helping some gator...  not_cyberbullying   \n",
              "\n",
              "                                              text_clean  text_len  \n",
              "4846   recuerda como nosotra tambin eramo victima del...        79  \n",
              "44294  dont want well fuck aint worth tear never swea...        73  \n",
              "45930  get ur ego trip take ur rose color glass amp g...        45  \n",
              "21241  yet god abl meet need use radic everyday gener...        43  \n",
              "41749  hoy mami keito aaaa okay um ikaw talaga one fi...        43  \n",
              "...                                                  ...       ...  \n",
              "44750                              fuck dumb nigger hate         4  \n",
              "1673                               lmao realli want take         4  \n",
              "35335                          grade school bulli coward         4  \n",
              "3920                                 need let anger dude         4  \n",
              "1377                          quietli help gator alreadi         4  \n",
              "\n",
              "[37113 rows x 4 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(by=[\"text_len\"], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9eNSclOgTS6"
      },
      "source": [
        "Sentiment column encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e2nns9igWqR"
      },
      "outputs": [],
      "source": [
        "df['sentiment'] = df['sentiment'].replace({'religion':0,'age':1,'ethnicity':2,'gender':3,'not_cyberbullying':4})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNXyyvFjgajB"
      },
      "source": [
        "Train - Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJfXXIDmgc8y"
      },
      "outputs": [],
      "source": [
        "X = df['text_clean']\n",
        "y = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E64pY16_gfQC"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Talupv8PgjIq"
      },
      "source": [
        "Train - Validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaO02oCrgigC"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j0N6GCngnk7",
        "outputId": "d24cd187-9119-41c2-aafd-eeb6aa69a835"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0, 5683],\n",
              "       [   1, 5638],\n",
              "       [   2, 5549],\n",
              "       [   3, 5264],\n",
              "       [   4, 4587]])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prVeN4BtgrLJ"
      },
      "source": [
        "Oversampling of training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H88PahvagqeY"
      },
      "outputs": [],
      "source": [
        "ros = RandomOverSampler()\n",
        "X_train, y_train = ros.fit_resample(np.array(X_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1));\n",
        "train_os = pd.DataFrame(list(zip([x[0] for x in X_train], y_train)), columns = ['text_clean', 'sentiment']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP7L0MCUgwjS"
      },
      "outputs": [],
      "source": [
        "X_train = train_os['text_clean'].values\n",
        "y_train = train_os['sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwlhxIH7gzki",
        "outputId": "a5da0ab9-82a4-4f61-ffd3-41cac73a11eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0, 5683],\n",
              "       [   1, 5683],\n",
              "       [   2, 5683],\n",
              "       [   3, 5683],\n",
              "       [   4, 5683]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diGquvlYg2ex"
      },
      "source": [
        "Naive Bayes baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTBWvgFxg4eJ"
      },
      "outputs": [],
      "source": [
        "clf = CountVectorizer()\n",
        "X_train_cv =  clf.fit_transform(X_train)\n",
        "X_test_cv = clf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg36P6dfg8s6"
      },
      "outputs": [],
      "source": [
        "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n",
        "X_train_tf = tf_transformer.transform(X_train_cv)\n",
        "X_test_tf = tf_transformer.transform(X_test_cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja741qMGhB7a"
      },
      "source": [
        "** Naive Bayes model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7japTP2UhAfJ"
      },
      "outputs": [],
      "source": [
        "nb_clf = MultinomialNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LOxOxGkhHi6",
        "outputId": "5f964889-a9db-46a0-8566-c08ab3f3be55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb_clf.fit(X_train_tf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1avhKp8UhKzC"
      },
      "outputs": [],
      "source": [
        "nb_pred = nb_clf.predict(X_test_tf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQF5WhGkhOQa",
        "outputId": "1a96fe35-5fa3-49ff-b1e9-dcdb1ca72024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    religion       0.85      0.97      0.91      1579\n",
            "         age       0.80      0.98      0.88      1566\n",
            "   ethnicity       0.90      0.92      0.91      1542\n",
            "      gender       0.89      0.85      0.87      1462\n",
            "not bullying       0.84      0.47      0.60      1274\n",
            "\n",
            "    accuracy                           0.85      7423\n",
            "   macro avg       0.86      0.84      0.84      7423\n",
            "weighted avg       0.86      0.85      0.84      7423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Classification Report for Naive Bayes:\\n',classification_report(y_test, nb_pred, target_names=sentiments))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lquLi_KhYMZ"
      },
      "source": [
        "confusion matrix skipped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnk8lxiMhbex"
      },
      "source": [
        "PyTorch Bi-LSTM RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9uSmit2heQB"
      },
      "source": [
        "Data preprocessing for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQEtiZV3hX7y"
      },
      "outputs": [],
      "source": [
        "def Tokenize(column, seq_len):\n",
        "    ##Create vocabulary of words from column\n",
        "    corpus = [word for text in column for word in text.split()]\n",
        "    count_words = Counter(corpus)\n",
        "    sorted_words = count_words.most_common()\n",
        "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "    ##Tokenize the columns text using the vocabulary\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        r = [vocab_to_int[word] for word in text.split()]\n",
        "        text_int.append(r)\n",
        "    ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for i, review in enumerate(text_int):\n",
        "        if len(review) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(review)))\n",
        "            new = zeros + review\n",
        "        else:\n",
        "            new = review[: seq_len]\n",
        "        features[i, :] = np.array(new)\n",
        "\n",
        "    return sorted_words, features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVd05ZYlhzop"
      },
      "outputs": [],
      "source": [
        "vocabulary, tokenized_column = Tokenize(df[\"text_clean\"], max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnBCemV4h-7q"
      },
      "source": [
        "We can check how each tweet has been tokenized with an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WCSkzeXiiBWY",
        "outputId": "7f83df74-e546-4bed-f313-a16dc6279824"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'love best respons hotcak manag film noncommitt meh adolesc mkr'"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"text_clean\"].iloc[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu_C_6fdiFaw",
        "outputId": "b07459c4-e1ec-4336-f99a-4b7dab684ea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,    66,   219,   503,\n",
              "        8001,  1300,  1142, 13587,  4686,  9804,    34])"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_column[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2enBkGUMiKdY"
      },
      "outputs": [],
      "source": [
        "keys = []\n",
        "values = []\n",
        "for key, value in vocabulary[:20]:\n",
        "    keys.append(key)\n",
        "    values.append(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXaU4HK-iOOp"
      },
      "source": [
        "Word Embedding by Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s_xR-IliQWD"
      },
      "outputs": [],
      "source": [
        "Word2vec_train_data = list(map(lambda x: x.split(), X_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrqxtqq2iUt8"
      },
      "source": [
        "We set a dimension of the embedding words, which can be seen as the number of featurs of each transformed word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0a3uWzLiXQr"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49wB_z06ikrQ",
        "outputId": "fc9b48a8-6ba7-4765-99b8-9d8798cdaa62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 33009\n"
          ]
        }
      ],
      "source": [
        "print(f\"Vocabulary size: {len(vocabulary) + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPgnnLWZip8P"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(vocabulary) + 1 #+1 for the padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpxnP0CAjXHa"
      },
      "source": [
        "skipped embedded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMNYT6MJjaaY"
      },
      "source": [
        "Train - Validation - Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psNeT0f5jZg4"
      },
      "outputs": [],
      "source": [
        "X = tokenized_column\n",
        "y = df['sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmm3CZOljrT8"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jeXdNS9juEY"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSwADq9ajwmg"
      },
      "source": [
        "We can check the balance of the target classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDkh8-q4jyaI",
        "outputId": "cbb7ba21-0b66-4b4e-a769-81eeed2b5491"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0, 5683],\n",
              "       [   1, 5638],\n",
              "       [   2, 5549],\n",
              "       [   3, 5264],\n",
              "       [   4, 4587]])"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(unique, counts) = np.unique(y_train, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjDv2jmmj2Rr"
      },
      "source": [
        "And then apply random oversampling on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39IUKYllj1Wk"
      },
      "outputs": [],
      "source": [
        "ros = RandomOverSampler()\n",
        "X_train_os, y_train_os = ros.fit_resample(np.array(X_train),np.array(y_train));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPFLfUuHj7CE",
        "outputId": "fc5fb1bb-954f-4a59-8ef9-c7bbd0b238e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0, 5683],\n",
              "       [   1, 5683],\n",
              "       [   2, 5683],\n",
              "       [   3, 5683],\n",
              "       [   4, 5683]])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(unique, counts) = np.unique(y_train_os, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrIdra3mj-iB"
      },
      "source": [
        "PyTorch datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5N0VISZj9nB"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train_os), torch.from_numpy(y_train_os))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdwVVR0kkDbo"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skm9OfI1kF4J"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmzM1rrFkIf8"
      },
      "source": [
        "PyTorch LSTM modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdXQcCcskKW8"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 5 #We are dealing with a multiclass classification of 5 classes\n",
        "HIDDEN_DIM = 100 #number of neurons of the internal state (internal neural network in the LSTM)\n",
        "LSTM_LAYERS = 1 #Number of stacked LSTM layers\n",
        "\n",
        "LR = 3e-4 #Learning rate\n",
        "DROPOUT = 0.5 #LSTM Dropout\n",
        "BIDIRECTIONAL = True #Boolean value to choose if to use a bidirectional LSTM or not\n",
        "EPOCHS = 5 #Number of training epoch\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48hxfzerkOOj"
      },
      "outputs": [],
      "source": [
        "class BiLSTM_Sentiment_Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, lstm_layers, bidirectional,batch_size, dropout):\n",
        "        super(BiLSTM_Sentiment_Classifier,self).__init__()\n",
        "\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers=lstm_layers,\n",
        "                            dropout=dropout,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim*self.num_directions, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        self.batch_size = x.size(0)\n",
        "        ##EMBEDDING LAYER\n",
        "        embedded = self.embedding(x)\n",
        "        #LSTM LAYERS\n",
        "        out, hidden = self.lstm(embedded, hidden)\n",
        "        #Extract only the hidden state from the last LSTM cell\n",
        "        out = out[:,-1,:]\n",
        "        #FULLY CONNECTED LAYERS\n",
        "        out = self.fc(out)\n",
        "        out = self.softmax(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        #Initialization of the LSTM hidden and cell states\n",
        "        h0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n",
        "        c0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(DEVICE)\n",
        "        hidden = (h0, c0)\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thfjNjmmkTt4",
        "outputId": "2bcb00c5-0d22-491c-94f5-bcb9e3073859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BiLSTM_Sentiment_Classifier(\n",
            "  (embedding): Embedding(33009, 200)\n",
            "  (lstm): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ],
      "source": [
        "model = BiLSTM_Sentiment_Classifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM,NUM_CLASSES, LSTM_LAYERS,BIDIRECTIONAL, BATCH_SIZE, DROPOUT)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "#Initialize embedding with the previously defined embedding matrix\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "#Allow the embedding matrix to be fined tuned to better adapt to out dataset and get higher accuracy\n",
        "model.embedding.weight.requires_grad=True\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqk-GS4ukYKr"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay = 5e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUah7Unoka4Z"
      },
      "source": [
        "LSTM Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9knc9-a0kdWa",
        "outputId": "d254067c-2bb6-4355-a7e1-56c4888e4857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:Validation accuracy increased (0.000000 --> 92.900815).  Saving model ...\n",
            "\tTrain_loss : 0.4957 Val_loss : 0.2130\n",
            "\tTrain_acc : 82.980% Val_acc : 92.901%\n",
            "Epoch 2:Validation accuracy increased (92.900815 --> 92.900815).  Saving model ...\n",
            "\tTrain_loss : 0.1520 Val_loss : 0.2132\n",
            "\tTrain_acc : 95.057% Val_acc : 92.901%\n",
            "Epoch 3:Validation accuracy increased (92.900815 --> 92.934783).  Saving model ...\n",
            "\tTrain_loss : 0.0915 Val_loss : 0.2365\n",
            "\tTrain_acc : 97.062% Val_acc : 92.935%\n",
            "Epoch 4:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0553 Val_loss : 0.2826\n",
            "\tTrain_acc : 98.253% Val_acc : 92.255%\n",
            "Epoch 5:Validation accuracy did not increase\n",
            "\tTrain_loss : 0.0405 Val_loss : 0.3036\n",
            "\tTrain_acc : 98.806% Val_acc : 91.984%\n"
          ]
        }
      ],
      "source": [
        "total_step = len(train_loader)\n",
        "total_step_val = len(valid_loader)\n",
        "\n",
        "early_stopping_patience = 4\n",
        "early_stopping_counter = 0\n",
        "\n",
        "valid_acc_max = 0 # Initialize best accuracy top 0\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "\n",
        "    #lists to host the train and validation losses of every batch for each epoch\n",
        "    train_loss, valid_loss  = [], []\n",
        "    #lists to host the train and validation accuracy of every batch for each epoch\n",
        "    train_acc, valid_acc  = [], []\n",
        "\n",
        "    #lists to host the train and validation predictions of every batch for each epoch\n",
        "    y_train_list, y_val_list = [], []\n",
        "\n",
        "    #initalize number of total and correctly classified texts during training and validation\n",
        "    correct, correct_val = 0, 0\n",
        "    total, total_val = 0, 0\n",
        "    running_loss, running_loss_val = 0, 0\n",
        "\n",
        "\n",
        "    ####TRAINING LOOP####\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE) #load features and targets in device\n",
        "\n",
        "        h = model.init_hidden(labels.size(0))\n",
        "\n",
        "        model.zero_grad() #reset gradients\n",
        "\n",
        "        output, h = model(inputs,h) #get output and hidden states from LSTM network\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred_train = torch.argmax(output, dim=1) #get tensor of predicted values on the training set\n",
        "        y_train_list.extend(y_pred_train.squeeze().tolist()) #transform tensor to list and the values to the list\n",
        "\n",
        "        correct += torch.sum(y_pred_train==labels).item() #count correctly classified texts per batch\n",
        "        total += labels.size(0) #count total texts per batch\n",
        "\n",
        "    train_loss.append(running_loss / total_step)\n",
        "    train_acc.append(100 * correct / total)\n",
        "\n",
        "    ####VALIDATION LOOP####\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            val_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "\n",
        "            val_loss = criterion(output, labels)\n",
        "            running_loss_val += val_loss.item()\n",
        "\n",
        "            y_pred_val = torch.argmax(output, dim=1)\n",
        "            y_val_list.extend(y_pred_val.squeeze().tolist())\n",
        "\n",
        "            correct_val += torch.sum(y_pred_val==labels).item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "        valid_loss.append(running_loss_val / total_step_val)\n",
        "        valid_acc.append(100 * correct_val / total_val)\n",
        "\n",
        "    #Save model if validation accuracy increases\n",
        "    if np.mean(valid_acc) >= valid_acc_max:\n",
        "        torch.save(model.state_dict(), './state_dict.pt')\n",
        "        print(f'Epoch {e+1}:Validation accuracy increased ({valid_acc_max:.6f} --> {np.mean(valid_acc):.6f}).  Saving model ...')\n",
        "        valid_acc_max = np.mean(valid_acc)\n",
        "        early_stopping_counter=0 #reset counter if validation accuracy increases\n",
        "    else:\n",
        "        print(f'Epoch {e+1}:Validation accuracy did not increase')\n",
        "        early_stopping_counter+=1 #increase counter if validation accuracy does not increase\n",
        "\n",
        "    if early_stopping_counter > early_stopping_patience:\n",
        "        print('Early stopped at epoch :', e+1)\n",
        "        break\n",
        "\n",
        "    print(f'\\tTrain_loss : {np.mean(train_loss):.4f} Val_loss : {np.mean(valid_loss):.4f}')\n",
        "    print(f'\\tTrain_acc : {np.mean(train_acc):.3f}% Val_acc : {np.mean(valid_acc):.3f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1XXqnp0oUjH"
      },
      "source": [
        "Loading the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gE6iCuDoOH2",
        "outputId": "7231be19-6b51-4c2a-de4a-dfd62da77f61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('./state_dict.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceGG7VK9ob74"
      },
      "source": [
        "LSTM Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnxoTCjIobOB"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "y_pred_list = []\n",
        "y_test_list = []\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "    test_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "    output, val_h = model(inputs, test_h)\n",
        "    y_pred_test = torch.argmax(output, dim=1)\n",
        "    y_pred_list.extend(y_pred_test.squeeze().tolist())\n",
        "    y_test_list.extend(labels.squeeze().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJZW2TnMokLH",
        "outputId": "66d59bd1-5505-4cdf-8f6c-c1c12ae70f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for Bi-LSTM :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    religion       0.96      0.94      0.95      1572\n",
            "         age       0.96      0.98      0.97      1560\n",
            "   ethnicity       0.97      0.98      0.98      1535\n",
            "      gender       0.94      0.87      0.90      1456\n",
            "not bullying       0.80      0.85      0.82      1269\n",
            "\n",
            "    accuracy                           0.93      7392\n",
            "   macro avg       0.93      0.93      0.92      7392\n",
            "weighted avg       0.93      0.93      0.93      7392\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Classification Report for Bi-LSTM :\\n', classification_report(y_test_list, y_pred_list, target_names=sentiments))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report Cyberbullying if detected\n"
      ],
      "metadata": {
        "id": "jWs1TV-IOO5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def report_cyberbullying(text, predicted_label, threshold=0.5):\n",
        "    if predicted_label == 1 and threshold >= 0.5:\n",
        "        # print(f\"The following text contains cyberbullying REPORTED WARNING: {text}\")\n",
        "        print(f\"\\033[91mThe following text contains cyberbullying REPORTED WARNING: {text}\\033[0m\")\n",
        "        # code to report the cyberbullying (e.g. contacting website administrators, law enforcement, etc.)\n",
        "    elif predicted_label == 1 and threshold < 0.5:\n",
        "        print(f\"The following text may contain cyberbullying REPORTED WARNING: {text}\")\n",
        "        # code to issue a warning to the user (e.g. display a warning message, flag the message, etc.)\n",
        "    else:\n",
        "        print(f\"The following text does not contain cyberbullying: {text}\")"
      ],
      "metadata": {
        "id": "BJshuY4tOLgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You are stupid and ugly\"\n",
        "predicted_label = 1\n",
        "threshold = 0.7\n",
        "\n",
        "report_cyberbullying(text, predicted_label, threshold)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlwMoZkcP6R3",
        "outputId": "e67b0890-fc70-489d-f91b-ae077f421a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mThe following text contains cyberbullying REPORTED WARNING: You are stupid and ugly\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You are smart and beautiful\"\n",
        "predicted_label = 0\n",
        "threshold = 0.7\n",
        "\n",
        "report_cyberbullying(text, predicted_label, threshold)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM-GSJjsQ3Om",
        "outputId": "ad5c3ea1-68f8-46fc-97ff-497fcd2bc8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following text does not contain cyberbullying: You are smart and beautiful\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}